{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Competition_Code_Pytorch_002",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ysFDltS95iB"
      },
      "source": [
        "# INSTALL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go2-ulwW9bOD"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTj8Q0wGA3lB"
      },
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HALQ4VHhA3pJ",
        "outputId": "9205a9ae-3409-4207-8fcc-67da6a39c481"
      },
      "source": [
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qat7mT3ZA-Es"
      },
      "source": [
        "%%bash\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip3 install /tmp/mecab-python-0.996"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8DyLUZhUuHn"
      },
      "source": [
        "# DATA_01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW_WgWlTA-IE"
      },
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Kkma, Komoran, Hannanum, Okt\n",
        "from konlpy.utils import pprint\n",
        "from konlpy.tag import Mecab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-FnoFnzA3tB",
        "outputId": "899b400c-6b44-4416-ddb5-44256abad7cf"
      },
      "source": [
        "mecab = Mecab()\n",
        "sentence = \"안녕하세요 저는 상휴입니다.\"\n",
        "temp_X = mecab.morphs(sentence)\n",
        "temp_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['안녕', '하', '세요', '저', '는', '상', '휴', '입니다', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtBw3pdw94aU"
      },
      "source": [
        "#!pip install Mecab_Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXcnaq2f9VgH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJCdJf4E9bRh"
      },
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "258aq5M29pFZ"
      },
      "source": [
        "seed_everything(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVw9ru_p12BF",
        "outputId": "c0686ff4-ac42-465b-a4d7-3d107a97a7c8"
      },
      "source": [
        "# google drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STY2YyZc9_c6"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf6AN9mG9sDm",
        "outputId": "61753597-1e32-4549-c493-3261d01f3477"
      },
      "source": [
        "# data dir\n",
        "data_dir = '/content/drive/MyDrive/6_수업자료/강의자료.최종/data'\n",
        "os.listdir(data_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ai-hub-nmt', 'chatbot', 'korquad', 'songys-chat', 'sts', 'nsmc', 'kowiki']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3E6M5w49sGy",
        "outputId": "1dcd0af7-d34a-4e42-d436-e117deb1a005"
      },
      "source": [
        "korquad_dir = os.path.join(data_dir, \"korquad\")\n",
        "if not os.path.isdir(korquad_dir):\n",
        "    os.makedirs(korquad_dir)\n",
        "os.listdir(korquad_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert-with-pre.csv', 'bert-with-pre.hdf5']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsfwItvk9bUY"
      },
      "source": [
        "# # vocab loading\n",
        "# vocab = spm.SentencePieceProcessor()\n",
        "# vocab.load(os.path.join(data_dir, 'kowiki', 'kowiki_32000.model'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XxA44fg9bXa",
        "outputId": "a5413596-0e83-4295-e653-8f40729ef272"
      },
      "source": [
        "# data dir\n",
        "data_dir_01 = '/content/drive/MyDrive/10. 문서요약 NLP /data_aihub/Training/신문기사_train_original/'\n",
        "os.listdir(data_dir_01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_original.json']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb-VlZjE-Xft"
      },
      "source": [
        "# 뒤에 저장된 df2를 로드할 것이므로..\n",
        "# with open(os.path.join(data_dir_01, 'train_original.json')) as f:\n",
        "#   train_json = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKTfW6xE-Xjw"
      },
      "source": [
        "### make data\n",
        "def df_maker():\n",
        "  dataset = []\n",
        "  for document in tqdm(train_json['documents']):\n",
        "    context_str=''\n",
        "\n",
        "    id = document['id']\n",
        "    title = document['title']\n",
        "    summary = document['abstractive'][0]\n",
        "\n",
        "    for sentence in document['text']:\n",
        "      for sentence_txt in sentence:\n",
        "        context_str += sentence_txt['sentence']\n",
        "        context_str += ' '\n",
        "    context = context_str  \n",
        "    row = {'id':id, 'title':title, 'context': context, 'summary': summary}\n",
        "    dataset.append(row)\n",
        "  df = pd.DataFrame(dataset)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlHmMhi7-znL"
      },
      "source": [
        "#df = df_maker()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Pd1fxn-zto"
      },
      "source": [
        "data_dir2 = '/content/drive/MyDrive/10. 문서요약 NLP /data_aihub/Training/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaVDcQPk_BTS"
      },
      "source": [
        "df2 = pd.read_csv(os.path.join(data_dir2, 'saved_df'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ABTHpHvf_BWo",
        "outputId": "e4f9fcbf-573c-4dbe-f020-746b5105a559"
      },
      "source": [
        "df2[0:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>290741778</td>\n",
              "      <td>논 타작물 재배, 2월 말까지 신청하세요</td>\n",
              "      <td>ha당 조사료 400만원…작물별 차등 지원 이성훈 sinawi@hanmail.net...</td>\n",
              "      <td>전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>290741792</td>\n",
              "      <td>여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성</td>\n",
              "      <td>8억 투입, 고소천사벽화·자산마을에 색채 입혀 이성훈 sinawi@hanmail.n...</td>\n",
              "      <td>여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>290741793</td>\n",
              "      <td>“새해 정기 받고 올해는 반드시 일내자!”</td>\n",
              "      <td>전남드래곤즈 해맞이 다짐…선수 영입 활발 이성훈 sinawi@hanmail.net ...</td>\n",
              "      <td>전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구단...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            summary\n",
              "0           0  ...  전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대...\n",
              "1           1  ...  여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천사...\n",
              "2           2  ...  전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구단...\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGligEXr_BZf"
      },
      "source": [
        "sample_length = int(len(df2)*0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utwiLZt__Bch"
      },
      "source": [
        "df3 = df2.iloc[0:sample_length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbMxR7Uku_os"
      },
      "source": [
        "#df2 = df2.drop([78540, 89353, 150941, 204862])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuM9poMAu8Sm",
        "outputId": "be9dae15-4f77-4446-9972-abc4c8205670"
      },
      "source": [
        "blank =[]\n",
        "for i,txt in enumerate(df3.summary):\n",
        "  if type(txt) != str:\n",
        "    blank.append(i)\n",
        "print(blank)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEL5G-E_idei",
        "outputId": "0181b02f-77c3-44d7-c1ef-b0c7c455f06a"
      },
      "source": [
        "len(df3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27109"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mdnoAe__Bfh"
      },
      "source": [
        "# HyperParameters\n",
        "\n",
        "encoder_len = 500\n",
        "decoder_len = 50\n",
        "max_vocab_size = 20000\n",
        "batch_size = 64\n",
        "num_layers = 6\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "epochs = 13\n",
        "learning_rate = 1e-4\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHEIiibJ_kHv"
      },
      "source": [
        "df_train = df3.iloc[:-200]\n",
        "df_val = df3.iloc[-200:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftt0cJa3_rik"
      },
      "source": [
        "# Tokenizing \n",
        "\n",
        "class Mecab_Tokenizer():\n",
        "    def __init__(self, max_length, mode, max_vocab_size=-1):\n",
        "        self.text_tokenizer = Mecab()\n",
        "        self.mode = mode\n",
        "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
        "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
        "        self.max_length = max_length\n",
        "        self.word_count = {}\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        \n",
        "        # 띄어쓰기를 찾기 위한 태그 목록\n",
        "        self.font_blank_tag = [\n",
        "            '', 'EC', 'EC+JKO', 'EF', 'EP+EC', 'EP+EP+EC', 'EP+ETM', 'EP+ETN+JKO', 'ETM', 'ETN', 'ETN+JKO', 'ETN+JX', 'IC', 'JC', 'JKB', 'JKB+JX', 'JKO',\n",
        "            'JKQ', 'JKS', 'JX', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ','MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+JKO', 'NNB+VCP+EC', 'NNBC', 'NNG', 'NNG+JX+JKO',\n",
        "            'NNG+VCP+EC', 'NNP', 'NNP+JX', 'NP', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NR', 'SC', 'SF', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'UNKNOWN',\n",
        "            'VA+EC', 'VA+EC+VX+ETM', 'VA+ETM', 'VA+ETN+JKB+JX', 'VCN+EC', 'VCN+ETM', 'VCP', 'VCP+EC', 'VCP+EP+EC', 'VCP+EP+ETM', 'VCP+ETM', 'VCP+ETN',\n",
        "            'VV+EC', 'VV+EC+JX', 'VV+EC+VX+EC', 'VV+EC+VX+ETM', 'VV+EP+EC', 'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VX+EC', 'VX+EC+VX+EP+EC', 'VX+EP+ETM',\n",
        "            'VX+ETM', 'XPN', 'XR', 'XSA+EC', 'XSA+EC+VX+ETM', 'XSA+ETM', 'XSN', 'XSV+EC', 'XSV+EP+EC', 'XSV+ETM', 'XSV+ETN', 'XSV+JKO'\n",
        "        ]\n",
        "        self.back_blank_tag = [\n",
        "            '', 'IC', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ', 'MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+VCP', 'NNB+VCP+EC', 'NNB+VCP+EF', 'NNBC', 'NNBC+VCP+EC',\n",
        "            'NNG', 'NNG+JC', 'NNG+JX+JKO', 'NNG+VCP', 'NNG+VCP+EC', 'NNG+VCP+ETM', 'NNP', 'NNP+JX', 'NP', 'NP+JKG', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NP+VCP+EF',\n",
        "            'NR', 'SC', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VA+EC', 'VA+EC+VX+ETM', 'VA+EF', 'VA+ETM', 'VA+ETN', 'VA+ETN+JKB+JX', 'VCN', 'VCN+EC', 'VCN+EF', 'VCN+ETM',\n",
        "            'VCN+ETN', 'VCP', 'VCP+EF', 'VV', 'VV+EC', 'VV+EC+JX', 'VV+EC+VX', 'VV+EC+VX+EC', 'VV+EC+VX+EF', 'VV+EC+VX+EP+EC', 'VV+EC+VX+ETM', 'VV+EF', 'VV+EP', 'VV+EP+EC',\n",
        "            'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VV+ETN+VCP+EF', 'VX', 'VX+ETM', 'XPN', 'XR', 'XSA+ETN+VCP+EF', 'XSN'\n",
        "        ]\n",
        "        \n",
        "    def morpheme(self, sentence_list):\n",
        "        new_sentence = []\n",
        "        for i, sentence in tqdm(enumerate(sentence_list)):\n",
        "            temp = []\n",
        "            if self.mode == 'dec':\n",
        "                temp.append('sos_')\n",
        "            for t in self.text_tokenizer.pos(sentence):\n",
        "                temp.append('_'.join(t))\n",
        "            if self.mode == 'dec':\n",
        "                temp.append('eos_')\n",
        "            new_sentence.append(' '.join(temp))\n",
        "            \n",
        "        return new_sentence\n",
        "    \n",
        "    def fit(self, sentence_list):\n",
        "        for sentence in tqdm(sentence_list):\n",
        "            for word in sentence.split(' '):\n",
        "                try:\n",
        "                    self.word_count[word] += 1\n",
        "                except:\n",
        "                    self.word_count[word] = 1\n",
        "        self.word_count = dict(sorted(self.word_count.items(), key=self.sort_target, reverse=True))\n",
        "        \n",
        "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
        "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
        "        if self.max_vocab_size == -1:\n",
        "            for i, word in enumerate(list(self.word_count.keys())):\n",
        "                self.txt2idx[word]=i+2\n",
        "                self.idx2txt[i+2]=word\n",
        "        else:\n",
        "            for i, word in enumerate(list(self.word_count.keys())[:self.max_vocab_size]):\n",
        "                self.txt2idx[word]=i+2\n",
        "                self.idx2txt[i+2]=word\n",
        "        \n",
        "    def sort_target(self, x):\n",
        "        return x[1]\n",
        "            \n",
        "    def txt2token(self, sentence_list):\n",
        "        tokens = []\n",
        "        for sentence in tqdm(sentence_list):\n",
        "            token = [0]*self.max_length\n",
        "            for i, w in enumerate(sentence.split(' ')):\n",
        "                if i == self.max_length:\n",
        "                    break\n",
        "                try:\n",
        "                    token[i] = self.txt2idx[w]\n",
        "                except:\n",
        "                    token[i] = self.txt2idx['unk_']\n",
        "            tokens.append(token)\n",
        "        return np.array(tokens)\n",
        "    \n",
        "    def convert(self, token):\n",
        "        sentence = []\n",
        "        for j, i in enumerate(token):\n",
        "            if self.mode == 'enc':\n",
        "                if i != self.txt2idx['pad_']:\n",
        "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
        "            elif self.mode == 'dec':\n",
        "                if i == self.txt2idx['eos_'] or i == self.txt2idx['pad_']:\n",
        "                    break\n",
        "                elif i != 0:\n",
        "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
        "                    # 앞뒤 태그를 확인하여 띄어쓰기 추가\n",
        "                    if self.idx2txt[i].split('_')[1] in self.font_blank_tag:\n",
        "                        try:\n",
        "                            if self.idx2txt[token[j+1]].split('_')[1] in self.back_blank_tag:\n",
        "                                sentence.append(' ')\n",
        "                        except:\n",
        "                            pass\n",
        "        sentence = \"\".join(sentence)\n",
        "        if self.mode == 'enc':\n",
        "            sentence = sentence[:-1]\n",
        "        elif self.mode == 'dec':\n",
        "            sentence = sentence[3:-1]\n",
        "            \n",
        "        return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ISnQQ-_6Q1"
      },
      "source": [
        "src_tokenizer = Mecab_Tokenizer(encoder_len, mode='enc', max_vocab_size=max_vocab_size)\n",
        "tar_tokenizer = Mecab_Tokenizer(decoder_len, mode='dec', max_vocab_size=max_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbiRFzvzPrEi",
        "outputId": "c4eeffb6-b0fd-4e2d-96d7-b18bc57451d9"
      },
      "source": [
        "train_src = src_tokenizer.morpheme(df_train.context)\n",
        "val_src = src_tokenizer.morpheme(df_val.context)\n",
        "#test_src = src_tokenizer.morpheme(test.context)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26909it [01:07, 397.00it/s]\n",
            "200it [00:00, 409.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsyznk96PvNe",
        "outputId": "75104718-6363-432a-8de6-acc7161f5018"
      },
      "source": [
        "train_tar = tar_tokenizer.morpheme(df_train.summary)\n",
        "val_tar = tar_tokenizer.morpheme(df_val.summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26909it [00:08, 3157.74it/s]\n",
            "200it [00:00, 2928.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zykO0gLaDD31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "3a28b1cc-1e27-4435-fcab-26dc6caf9829"
      },
      "source": [
        "train_src_len = []\n",
        "for m in train_src:\n",
        "    m_len = len(m.split(' '))\n",
        "    train_src_len.append(m_len)\n",
        "print('train_src_max_len :', max(train_src_len))\n",
        "plt.hist(train_src_len, bins=30)\n",
        "plt.show()\n",
        "\n",
        "train_tar_len = []\n",
        "for m in train_tar:\n",
        "    m_len = len(m.split(' '))\n",
        "    train_tar_len.append(m_len)\n",
        "print('train_tar_max_len :', max(train_tar_len))\n",
        "plt.hist(train_tar_len, bins=30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_src_max_len : 1076\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATIElEQVR4nO3df6zddX3H8efLIvgztsBd07Vlt7pOh8tW2Q3WuBknEwqaFRclJcvsHFuXDTLdlixFszF1JLi4OU0cs5Nu1TiROR0NMmtFl/1IBAoCtiDjCnW0KbQKos6MWHzvj+/nyqHe9p57e+49t9znIzm53+/7+znnvM+5p33dz/f7PeekqpAkLWzPGHYDkqThMwwkSYaBJMkwkCRhGEiSgJOG3cCxnH766TU6OjrsNiTphHLbbbd9o6pGpnOdeR0Go6Oj7Nq1a9htSNIJJcnXp3sddxNJkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIl5/g7kE9Xo5s/0NW7vVa+b5U4kqT/ODCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSfQRBkmeleSWJHcm2ZPkna2+KsnNScaTfCLJya1+Slsfb9tHe27r8la/N8l5s/WgJEnT08/M4HHgNVX1c8AaYF2StcB7gPdV1U8CjwKXtPGXAI+2+vvaOJKcCWwAXgqsA/4myaJBPhhJ0sxMGQbV+W5bfWa7FPAa4JOtvg24sC2vb+u07eckSatfW1WPV9UDwDhw9kAehSTpuPR1zCDJoiR3AAeBncDXgG9V1eE2ZB+wvC0vBx4EaNsfA07rrU9ynd772pRkV5Jdhw4dmv4jkiRNW19hUFVPVNUaYAXdX/Mvma2GqmpLVY1V1djIyMhs3Y0kqce0ziaqqm8BXwReASxOMvG1mSuA/W15P7ASoG1/AfDN3vok15EkDVE/ZxONJFnclp8NvBa4hy4U3tiGbQSub8vb2zpt+xeqqlp9QzvbaBWwGrhlUA9EkjRzJ009hGXAtnbmzzOA66rqhiR3A9cm+XPgy8A1bfw1wEeTjAOP0J1BRFXtSXIdcDdwGLi0qp4Y7MORJM3ElGFQVXcBL5ukfj+TnA1UVf8HvOkot3UlcOX025QkzSbfgSxJMgwkSYaBJAnDQJKEYSBJwjCQJNHf+ww0S0Y3f6avcXuvet0sdyJpoXNmIEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwk8tPSH0++mm4CecSpoZZwaSpKnDIMnKJF9McneSPUne2up/lmR/kjva5YKe61yeZDzJvUnO66mva7XxJJtn5yFJkqarn91Eh4E/qqrbkzwfuC3JzrbtfVX13t7BSc4ENgAvBX4c+HySn2qbPwi8FtgH3Jpke1XdPYgHIkmauSnDoKoOAAfa8neS3AMsP8ZV1gPXVtXjwANJxoGz27bxqrofIMm1baxhIElDNq1jBklGgZcBN7fSZUnuSrI1yZJWWw482HO1fa12tPqR97Epya4kuw4dOjSd9iRJM9R3GCR5HvDPwNuq6tvA1cCLgDV0M4e/HERDVbWlqsaqamxkZGQQNylJmkJfp5YmeSZdEHysqj4FUFUP92z/O+CGtrofWNlz9RWtxjHqkqQh6udsogDXAPdU1V/11Jf1DHsDsLstbwc2JDklySpgNXALcCuwOsmqJCfTHWTePpiHIUk6Hv3MDF4J/DrwlSR3tNrbgYuTrAEK2Av8DkBV7UlyHd2B4cPApVX1BECSy4AdwCJga1XtGeBjkSTNUD9nE/0nkEk23XiM61wJXDlJ/cZjXU+SNBy+A1mSZBhIkgwDSRKGgSQJw0CShGEgScIwkCThN51Ny3S+cUySTiTODCRJhoEkyTCQJGEYSJIwDCRJGAaSJDy19Gmn39Nf9171ulnuRNKJxJmBJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJNFHGCRZmeSLSe5OsifJW1v91CQ7k9zXfi5p9ST5QJLxJHclOavntja28fcl2Th7D0uSNB39zAwOA39UVWcCa4FLk5wJbAZuqqrVwE1tHeB8YHW7bAKuhi48gCuAlwNnA1dMBIgkabimDIOqOlBVt7fl7wD3AMuB9cC2NmwbcGFbXg98pDpfAhYnWQacB+ysqkeq6lFgJ7BuoI9GkjQj0zpmkGQUeBlwM7C0qg60TQ8BS9vycuDBnqvta7Wj1Y+8j01JdiXZdejQoem0J0maob7DIMnzgH8G3lZV3+7dVlUF1CAaqqotVTVWVWMjIyODuElJ0hT6CoMkz6QLgo9V1ada+eG2+4f282Cr7wdW9lx9RasdrS5JGrJ+ziYKcA1wT1X9Vc+m7cDEGUEbget76m9uZxWtBR5ru5N2AOcmWdIOHJ/bapKkIevn+wxeCfw68JUkd7Ta24GrgOuSXAJ8HbiobbsRuAAYB74HvAWgqh5J8m7g1jbuXVX1yEAehSTpuEwZBlX1n0COsvmcScYXcOlRbmsrsHU6DUqSZp/vQJYkGQaSJL8DecHyu5Il9XJmIEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJvwNZU/C7kqWFYcowSLIVeD1wsKp+ptX+DPht4FAb9vaqurFtuxy4BHgC+P2q2tHq64D3A4uAD1fVVYN9KBomQ0M6sfWzm+gfgHWT1N9XVWvaZSIIzgQ2AC9t1/mbJIuSLAI+CJwPnAlc3MZKkuaBKWcGVfXvSUb7vL31wLVV9TjwQJJx4Oy2bbyq7gdIcm0be/e0O5YkDdzxHEC+LMldSbYmWdJqy4EHe8bsa7Wj1X9Ekk1JdiXZdejQocmGSJIGbKZhcDXwImANcAD4y0E1VFVbqmqsqsZGRkYGdbOSpGOY0dlEVfXwxHKSvwNuaKv7gZU9Q1e0GseoS5KGbEYzgyTLelbfAOxuy9uBDUlOSbIKWA3cAtwKrE6yKsnJdAeZt8+8bUnSIPVzaunHgVcDpyfZB1wBvDrJGqCAvcDvAFTVniTX0R0YPgxcWlVPtNu5DNhBd2rp1qraM/BHI0makX7OJrp4kvI1xxh/JXDlJPUbgRun1Z0kaU74cRSSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSczw+wykmRrd/Jm+xu296nWz3ImkXs4MJEmGgSTJMJAkYRhIkjAMJEl4NpHmKc86kuaWMwNJkmEgSTIMJEn0EQZJtiY5mGR3T+3UJDuT3Nd+Lmn1JPlAkvEkdyU5q+c6G9v4+5JsnJ2HI0maiX5mBv8ArDuithm4qapWAze1dYDzgdXtsgm4GrrwAK4AXg6cDVwxESCSpOGbMgyq6t+BR44orwe2teVtwIU99Y9U50vA4iTLgPOAnVX1SFU9CuzkRwNGkjQkMz21dGlVHWjLDwFL2/Jy4MGecfta7Wj1H5FkE92sgjPOOGOG7Wmh6PcUVPA0VOlYjvsAclUVUAPoZeL2tlTVWFWNjYyMDOpmJUnHMNMweLjt/qH9PNjq+4GVPeNWtNrR6pKkeWCmYbAdmDgjaCNwfU/9ze2sorXAY2130g7g3CRL2oHjc1tNkjQPTHnMIMnHgVcDpyfZR3dW0FXAdUkuAb4OXNSG3whcAIwD3wPeAlBVjyR5N3BrG/euqjryoLQkaUimDIOquvgom86ZZGwBlx7ldrYCW6fVnSRpTvgOZEmSYSBJMgwkSRgGkiQMA0kShoEkCb/2UguIX6UpHZ0zA0mSMwPpSM4gtBA5M5AkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEr4DWZox36mspxNnBpIkw0CSZBhIkjAMJEkc5wHkJHuB7wBPAIeraizJqcAngFFgL3BRVT2aJMD7gQuA7wG/UVW3H8/9SycCDzTrRDCImcEvVdWaqhpr65uBm6pqNXBTWwc4H1jdLpuAqwdw35KkAZiN3UTrgW1teRtwYU/9I9X5ErA4ybJZuH9J0jQd7/sMCvhckgI+VFVbgKVVdaBtfwhY2paXAw/2XHdfqx3oqZFkE93MgTPOOOM425NOHO5O0jAdbxj8QlXtT/JjwM4kX+3dWFXVgqJvLVC2AIyNjU3rupKkmTmu3URVtb/9PAh8GjgbeHhi90/7ebAN3w+s7Ln6ilaTJA3ZjMMgyXOTPH9iGTgX2A1sBza2YRuB69vyduDN6awFHuvZnSRJGqLj2U20FPh0d8YoJwH/WFWfTXIrcF2SS4CvAxe18TfSnVY6Tndq6VuO474lSQM04zCoqvuBn5uk/k3gnEnqBVw60/uTJM0eP7VUOsF41pFmgx9HIUkyDCRJ7iaSnrb63Z0E7lKSMwNJEoaBJAl3EwHTm05L0tORMwNJkmEgSXI3kSR8I5ucGUiScGYgaRqcQTx9OTOQJDkzkDR4ziBOPM4MJEnODCQNjzOI+cOZgSTJMJAkuZtI0gnA3Umzz5mBJMkwkCQZBpIkDANJEkM4gJxkHfB+YBHw4aq6aq57kPT05IHmmZvTMEiyCPgg8FpgH3Brku1Vdfdc9iFpYZvOtxsulOCY65nB2cB4Vd0PkORaYD0wK2Hg11lKOl4LZbYx12GwHHiwZ30f8PLeAUk2AZva6neT3DtHvfU6HfjGEO53KvOxL3vq33zsy576d8y+8p457ORJR+vpJ6Z7Q/PuTWdVtQXYMswekuyqqrFh9jCZ+diXPfVvPvZlT/2bj30Nsqe5PptoP7CyZ31Fq0mShmiuw+BWYHWSVUlOBjYA2+e4B0nSEeZ0N1FVHU5yGbCD7tTSrVW1Zy576NNQd1Mdw3zsy576Nx/7sqf+zce+BtZTqmpQtyVJOkH5DmRJkmEgSVqgYZDkWUluSXJnkj1J3tnqq5LcnGQ8ySfaQW6SnNLWx9v20VnsbVGSLye5YT70lGRvkq8kuSPJrlY7NcnOJPe1n0taPUk+0Hq6K8lZs9FTu6/FST6Z5KtJ7knyimH2leTF7TmauHw7yduG/Vwl+YP2Gt+d5OPttT/s19RbWz97kryt1eb8eUqyNcnBJLt7atPuI8nGNv6+JBtnoac3tefqB0nGjhh/eevp3iTn9dTXtdp4ks193XlVLbgLEOB5bfmZwM3AWuA6YEOr/y3wu23594C/bcsbgE/MYm9/CPwjcENbH2pPwF7g9CNqfwFsbsubgfe05QuAf23P71rg5ll8nrYBv9WWTwYWz4e+2v0tAh6ie+PP0Hqie5PnA8Cze15LvzHM1xTwM8Bu4Dl0J7B8HvjJYTxPwKuAs4DdM31tA6cC97efS9rykgH39NPAi4F/A8Z66mcCdwKnAKuAr7XX3qK2/ML2b+NO4Mwp73s2/1GcCJf2oryd7p3Q3wBOavVXADva8g7gFW35pDYus9DLCuAm4DXADe2FN+ye9vKjYXAvsKwtLwPubcsfAi6ebNyAe3oB3X9ymU999dz+ucB/DbsnnnzH/6ntNXIDcN4wX1PAm4Bretb/BPjjYT1PwChP/Y93Wn0AFwMf6qk/Zdwgeuqp/xtPDYPLgct71ne03+cPf6eTjTvaZUHuJoIf7o65AzgI7KRL0m9V1eE2ZB/dPybo+RiNtv0x4LRZaOuv6f5h/KCtnzYPeirgc0luS/dRIQBLq+pAW34IWHpkT5P0O0irgEPA36fbpfbhJM+dB31N2AB8vC0Praeq2g+8F/gf4ADda+Q2hvua2g38YpLTkjyH7i/ulcyf3910+5jr/noNtKcFGwZV9URVraH7a/xs4CXD7CfJ64GDVXXbMPuYxC9U1VnA+cClSV7Vu7G6Pz3m+vzkk+im0ldX1cuA/6Wb0g+7L9r+918B/unIbXPdU9vfvZ4uPH8ceC6wbq7ufzJVdQ/wHuBzwGeBO4AnjhgzlN/dkeZLH3NlwYbBhKr6FvBFuqnV4iQTb8Tr/aiMH36MRtv+AuCbA27llcCvJNkLXEu3q+j9Q+5p4q9Lquog8Gm64Hw4ybJ238voZldP6WmSfgdpH7Cvqm5u65+kC4dh9wVdaN5eVQ+39WH29MvAA1V1qKq+D3yK7nU27NfUNVX181X1KuBR4L+ZH787ZtDHMD9iZ6A9LcgwSDKSZHFbfjbd9yvcQxcKb2zDNgLXt+XtbZ22/Qvtr4aBqarLq2pFVY3S7Wb4QlX92jB7SvLcJM+fWKbbF777iPs+sqc3tzMv1gKP9Uy5B6aqHgIeTPLiVjqH7mPQh9pXczFP7iKauO9h9fQ/wNokz0kSnnyehvaaAkjyY+3nGcCv0p0wMR9+dxP3N50+dgDnJlnSZmLnttpc2A5saGeBrQJWA7cw04/9GdSBmBPpAvws8GXgLrr/3P601V/Ynsxxumn+Ka3+rLY+3ra/cJb7ezVPnk00tJ7afd/ZLnuAd7T6aXQHuu+jOxvk1FYP3ZcXfQ34Cj0Hu2ahtzXArvY7/Be6MzmG2hfdbphvAi/oqQ27p3cCX22v84/SnXky1Nc58B90oXQncM6wnie60D4AfJ9utnnJTPoAfrM9Z+PAW2ahpze05ceBh3nqweF3tJ7uBc7vqV9AN+P62sS/26kufhyFJGlh7iaSJD2VYSBJMgwkSYaBJAnDQJKEYSBJwjCQJAH/D3UGc11LZKkSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_tar_max_len : 263\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RHfJBW0wcvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bffd6f1-003d-48b0-8341-97cf263982e6"
      },
      "source": [
        "src_tokenizer.fit(train_src)\n",
        "tar_tokenizer.fit(train_tar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26909/26909 [00:04<00:00, 6181.09it/s]\n",
            "100%|██████████| 26909/26909 [00:00<00:00, 49853.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9GeuYlr_9vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d044d61-986e-44fa-88b5-cd93a14b047d"
      },
      "source": [
        "train_src_tokens = src_tokenizer.txt2token(train_src)\n",
        "val_src_tokens = src_tokenizer.txt2token(val_src)\n",
        "#test_src_tokens = src_tokenizer.txt2token(test_src)\n",
        "\n",
        "train_tar_tokens = tar_tokenizer.txt2token(train_tar)\n",
        "val_tar_tokens = tar_tokenizer.txt2token(val_tar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26909/26909 [00:04<00:00, 5564.60it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 6023.23it/s]\n",
            "100%|██████████| 26909/26909 [00:00<00:00, 50700.40it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 31559.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URwyPkNT_9yp"
      },
      "source": [
        "input_vocab_size = len(src_tokenizer.txt2idx)\n",
        "target_vocab_size = len(tar_tokenizer.txt2idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qowSm6mk_91w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0194ac6a-7e0e-4a6b-abd5-fa4584b475f9"
      },
      "source": [
        "input_vocab_size, target_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20002, 20002)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqVW7o_7w6Km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076114e7-e2b1-49de-fb32-831c39dc5d59"
      },
      "source": [
        "train_tar_tokens[0], tar_tokenizer.convert(train_tar_tokens[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([    5,  1053,    16,  1423,  5410,   204,     7,  3751,    36,\n",
              "           20,   420,     8,    39,    50,   178,    66,  3521,     7,\n",
              "         2601,    75,   125,  9391,     9, 11109,  2108,  6247,  3455,\n",
              "          843,  5256,    24,   837,  3455,     2,  2601,  1921,  3521,\n",
              "          188,     3,  1066,   848,   421,     7,  1941,    35,   323,\n",
              "           13,    15,  1423,   538,   803]),\n",
              " \" 전라남도가 쌀 과잉 문제를 근본 적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 대신 사료 작물이나 콩 등 다른 작물을 심으면 벼와의일정 소득 차를 보전해 주는 ' 쌀 생산 조\")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xUA_64Qw6NN"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, src_tokens, tar_tokens, mode='train'):\n",
        "        self.mode = mode\n",
        "        self.src_tokens = src_tokens\n",
        "        if self.mode == 'train':\n",
        "            self.tar_tokens = tar_tokens\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.src_tokens)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        src_token = self.src_tokens[i]\n",
        "        if self.mode == 'train':\n",
        "            tar_token = self.tar_tokens[i]\n",
        "            return {\n",
        "                'src_token' : torch.tensor(src_token, dtype=torch.long),\n",
        "                'tar_token' : torch.tensor(tar_token, dtype=torch.long),\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'src_token' : torch.tensor(src_token, dtype=torch.long)\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ5c2cY0xz5i"
      },
      "source": [
        "train_dataset = CustomDataset(train_src_tokens, train_tar_tokens)\n",
        "val_dataset = CustomDataset(val_src_tokens, val_tar_tokens)\n",
        "#test_dataset = CustomDataset(test_src_tokens, None, 'test')\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=False)\n",
        "#test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1GjFi-xw6Pt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Dl_DtAyGsb"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOjXYyJww6SH"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M60iZyGyLln"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return torch.tensor(pos_encoding, dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0yrYINFyP3S"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding\n",
        "    # to the attention logits.\n",
        "    seq = seq.unsqueeze(1).unsqueeze(2)\n",
        "    return seq  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7idpS24vyRSS"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = torch.ones(size, size).triu(diagonal=1)\n",
        "    return mask  # (seq_len, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtObdQcOyS3v"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = torch.matmul(q, torch.transpose(k, -2, -1))  # (..., seq_len_q, seq_len_k)\n",
        "    \n",
        "    # scale matmul_qk\n",
        "    dk = k.size()[-1]\n",
        "    scaled_attention_logits = matmul_qk / math.sqrt(dk)\n",
        "    \n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2otwq4JyUPY"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "    temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "    print('Attention weights are:')\n",
        "    print(temp_attn)\n",
        "    print('Output is:')\n",
        "    print(temp_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTDD98cqyWJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfb15ba-dfbd-4ddf-a9bd-cc5bc6c3d276"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = torch.tensor([[10, 0, 0],\n",
        "                      [0, 10, 0],\n",
        "                      [0, 0, 10],\n",
        "                      [0, 0, 10]], dtype=torch.float32)  # (4, 3)\n",
        "\n",
        "temp_v = torch.tensor([[1, 0],\n",
        "                      [10, 0],\n",
        "                      [100, 5],\n",
        "                      [1000, 6]], dtype=torch.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = torch.tensor([[0, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
            "Output is:\n",
            "tensor([[1.0000e+01, 9.2766e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Yc6tZxyXcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14967682-d715-4455-c49b-7927272ce640"
      },
      "source": [
        "temp_q = torch.tensor([[10, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
            "Output is:\n",
            "tensor([[5.5000e+00, 4.6383e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coR5MjvIyZY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85dde84-36cc-4595-82f6-ee5a0cc17124"
      },
      "source": [
        "temp_q = torch.tensor([[0, 0, 10],\n",
        "                      [0, 10, 0],\n",
        "                      [10, 10, 0]], dtype=torch.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[4.2166e-26, 4.2166e-26, 5.0000e-01, 5.0000e-01],\n",
            "        [8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26],\n",
            "        [5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
            "Output is:\n",
            "tensor([[5.5000e+02, 5.5000e+00],\n",
            "        [1.0000e+01, 9.2766e-25],\n",
            "        [5.5000e+00, 4.6383e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cla1HGiQyanO"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = nn.Linear(d_model, d_model)\n",
        "        self.wk = nn.Linear(d_model, d_model)\n",
        "        self.wv = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.wo = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, v, k, q, mask):\n",
        "        batch_size = q.size()[0]\n",
        "        \n",
        "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        \n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        \n",
        "        scaled_attention = scaled_attention.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.depth)\n",
        "                \n",
        "        output = self.wo(scaled_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHvSfdHycHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69e4029-cd94-419c-cead-30ae2a71bd41"
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = torch.rand(1, 60, 512)  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 60, 512]), torch.Size([1, 8, 60, 60]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoJRb-zYydjD"
      },
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, d_model, dff):\n",
        "        super(FFN, self).__init__()\n",
        "        self.layer1 = nn.Linear(d_model, dff)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.fc = nn.Linear(dff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMWeLyuBye0j"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = FFN(d_model, dff)\n",
        "        \n",
        "        self.layernorm1 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
        "        self.layernorm2 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(rate)\n",
        "        self.dropout2 = nn.Dropout(rate)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvSDh3wgygKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bef3988-5236-4a99-bf18-53989d46cc99"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048, encoder_len)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    torch.rand(64, encoder_len, 512), None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 500, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUQ86XV3yhqF"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        \n",
        "        self.ffn = FFN(d_model, dff)\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(rate)\n",
        "        self.dropout2 = nn.Dropout(rate)\n",
        "        self.dropout3 = nn.Dropout(rate)\n",
        "        \n",
        "        self.layernorms1 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "        self.layernorms2 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "        self.layernorms3 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "\n",
        "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1)\n",
        "        out1 = self.layernorms1[x.size(1)-1](attn1 + x)\n",
        "        \n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2)\n",
        "        out2 = self.layernorms2[x.size(1)-1](attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "        \n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output)\n",
        "        out3 = self.layernorms3[x.size(1)-1](ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "        \n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkYq-MdpylI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70e6ecc-15b3-45e9-b699-2b98d7e05733"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048, decoder_len)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    torch.rand(64, decoder_len, 512), sample_encoder_layer_output,\n",
        "    None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 50, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaMUlIR2ym5x"
      },
      "source": [
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM-VsJDjyohE"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
        "        \n",
        "        self.dec_layers = clones(EncoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "\n",
        "    def forward(self, x, mask, enc_output=None):\n",
        "        if enc_output == None:\n",
        "            seq_len = x.size()[1]\n",
        "            attention_weights = {}\n",
        "            x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "            x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
        "            x += self.pos_encoding[:, :seq_len, :]\n",
        "            x = self.dropout(x)\n",
        "            for i in range(self.num_layers):\n",
        "                x = self.dec_layers[i](x, mask)\n",
        "        else:\n",
        "            x = enc_output\n",
        "            \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAD9NeBCyp7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6168f46b-ecfd-4ca4-c52f-4ef5b0f2e137"
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, input_vocab_size=input_vocab_size,\n",
        "                         maximum_position_encoding=encoder_len,\n",
        "                         device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, mask=None, enc_output=None)\n",
        "\n",
        "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 500, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OveatKRfyrc5"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
        "        \n",
        "        self.dec_layers = clones(DecoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "        \n",
        "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        seq_len = x.size()[1]\n",
        "        attention_weights = {}\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "            \n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rhD-DDayPbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e22d90-9f79-4765-a840-13f4f6662296"
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, target_vocab_size=target_vocab_size,\n",
        "                         maximum_position_encoding=decoder_len,\n",
        "                         device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 50, 512]), torch.Size([64, 8, 50, 500]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeGpOjg5w6UQ"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, device, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                                 input_vocab_size, pe_input, device, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                               target_vocab_size, pe_target, device, rate)\n",
        "\n",
        "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inp, tar, enc_output = inputs\n",
        "\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
        "\n",
        "        enc_output = self.encoder(inp, enc_padding_mask, enc_output)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights, enc_output\n",
        "\n",
        "    def create_masks(self, inp, tar):\n",
        "        # Encoder padding mask\n",
        "        enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "        # Used in the 2nd attention block in the decoder.\n",
        "        # This padding mask is used to mask the encoder outputs.\n",
        "        dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "        # Used in the 1st attention block in the decoder.\n",
        "        # It is used to pad and mask future tokens in the input received by\n",
        "        # the decoder.\n",
        "        look_ahead_mask = create_look_ahead_mask(tar.size(1))\n",
        "        dec_target_padding_mask = create_padding_mask(tar)\n",
        "        look_ahead_mask = torch.maximum(dec_target_padding_mask.to(self.device), look_ahead_mask.to(self.device))\n",
        "\n",
        "        return enc_padding_mask, look_ahead_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-snmouu_0zoH",
        "outputId": "97abbc0d-9d07-4aab-ad06-2604c7a24904"
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
        "    input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size,\n",
        "    pe_input=encoder_len, pe_target=decoder_len, device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
        "temp_target = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
        "\n",
        "fn_out, _, _ = sample_transformer([temp_input, temp_target, None])\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 50, 20002])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9j_Wf760zuE"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=input_vocab_size,\n",
        "    target_vocab_size=target_vocab_size,\n",
        "    pe_input=encoder_len,\n",
        "    pe_target=decoder_len-1,\n",
        "    device=device,\n",
        "    rate=dropout_rate\n",
        ")\n",
        "\n",
        "transformer = transformer.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey0RWsfv06Fs"
      },
      "source": [
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywqURZkJ06IL"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    loss_ = criterion(pred.permute(0,2,1), real)\n",
        "    mask = torch.tensor(mask, dtype=loss_.dtype)\n",
        "    loss_ = mask * loss_\n",
        "\n",
        "    return torch.sum(loss_)/torch.sum(mask)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    accuracies = torch.logical_and(mask, accuracies)\n",
        "    accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
        "    mask = torch.tensor(mask, dtype=torch.float32)\n",
        "    \n",
        "    return torch.sum(accuracies)/torch.sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfn959aw06Kr"
      },
      "source": [
        "def train_step(batch_item, epoch, batch, training):\n",
        "    src = batch_item['src_token'].to(device)\n",
        "    tar = batch_item['tar_token'].to(device)\n",
        "    \n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    \n",
        "    if training is True:\n",
        "        transformer.train()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        return loss, acc, round(lr, 10)\n",
        "    else:\n",
        "        transformer.eval()\n",
        "        with torch.no_grad():\n",
        "            output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        return loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vPdvMWv06M1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OCPtaix1AUu"
      },
      "source": [
        "# TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBohdLpBs-pf"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bN2WEgA06Ot",
        "outputId": "c8229c2a-8787-488e-f63c-414ccfd7ed7a"
      },
      "source": [
        "loss_plot, val_loss_plot = [], []\n",
        "acc_plot, val_acc_plot = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gc.collect()\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_acc, total_val_acc = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc, lr = train_step(batch_item, epoch, batch, training)\n",
        "        total_loss += batch_loss\n",
        "        total_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'LR' : lr,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
        "            'Total ACC' : '{:06f}'.format(total_acc/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    acc_plot.append(total_acc/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, epoch, batch, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
        "            'Total Val ACC' : '{:06f}'.format(total_val_acc/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    val_acc_plot.append(total_val_acc/(batch+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "421it [08:05,  1.15s/it, Epoch=1, LR=0.0001, Loss=5.455896, Total Loss=6.393881, Total ACC=0.112976]\n",
            "4it [00:01,  2.73it/s, Epoch=1, Val Loss=5.726916, Total Val Loss=5.736567, Total Val ACC=0.161588]\n",
            "421it [08:06,  1.15s/it, Epoch=2, LR=0.0001, Loss=5.473673, Total Loss=5.454027, Total ACC=0.187515]\n",
            "4it [00:01,  2.71it/s, Epoch=2, Val Loss=5.435558, Total Val Loss=5.418797, Total Val ACC=0.192101]\n",
            "421it [08:06,  1.15s/it, Epoch=3, LR=0.0001, Loss=5.269340, Total Loss=5.217807, Total ACC=0.218948]\n",
            "4it [00:01,  2.70it/s, Epoch=3, Val Loss=5.173285, Total Val Loss=5.189062, Total Val ACC=0.225826]\n",
            "421it [08:06,  1.15s/it, Epoch=4, LR=0.0001, Loss=4.952197, Total Loss=5.072702, Total ACC=0.241900]\n",
            "4it [00:01,  2.69it/s, Epoch=4, Val Loss=5.100992, Total Val Loss=5.076311, Total Val ACC=0.242972]\n",
            "421it [08:06,  1.15s/it, Epoch=5, LR=0.0001, Loss=5.057333, Total Loss=4.970638, Total ACC=0.260950]\n",
            "4it [00:01,  2.69it/s, Epoch=5, Val Loss=5.040423, Total Val Loss=5.002623, Total Val ACC=0.253061]\n",
            "421it [08:06,  1.15s/it, Epoch=6, LR=0.0001, Loss=5.012514, Total Loss=4.889141, Total ACC=0.277521]\n",
            "4it [00:01,  2.68it/s, Epoch=6, Val Loss=4.997347, Total Val Loss=4.935263, Total Val ACC=0.262742]\n",
            "421it [08:06,  1.15s/it, Epoch=7, LR=0.0001, Loss=4.872572, Total Loss=4.828698, Total ACC=0.291825]\n",
            "4it [00:01,  2.65it/s, Epoch=7, Val Loss=4.937936, Total Val Loss=4.902398, Total Val ACC=0.278005]\n",
            "421it [08:06,  1.16s/it, Epoch=8, LR=0.0001, Loss=5.001375, Total Loss=4.787230, Total ACC=0.303597]\n",
            "4it [00:01,  2.67it/s, Epoch=8, Val Loss=4.880185, Total Val Loss=4.878818, Total Val ACC=0.286699]\n",
            "421it [08:06,  1.15s/it, Epoch=9, LR=0.0001, Loss=4.368338, Total Loss=4.770296, Total ACC=0.312341]\n",
            "4it [00:01,  2.65it/s, Epoch=9, Val Loss=4.818151, Total Val Loss=4.805731, Total Val ACC=0.303428]\n",
            "421it [08:06,  1.15s/it, Epoch=10, LR=0.0001, Loss=5.072898, Total Loss=4.752512, Total ACC=0.320891]\n",
            "4it [00:01,  2.64it/s, Epoch=10, Val Loss=4.817209, Total Val Loss=4.848304, Total Val ACC=0.302055]\n",
            "421it [08:06,  1.15s/it, Epoch=11, LR=0.0001, Loss=4.841563, Total Loss=4.738931, Total ACC=0.327926]\n",
            "4it [00:01,  2.61it/s, Epoch=11, Val Loss=4.892269, Total Val Loss=4.873683, Total Val ACC=0.303442]\n",
            "421it [08:06,  1.16s/it, Epoch=12, LR=0.0001, Loss=4.892376, Total Loss=4.763420, Total ACC=0.330000]\n",
            "4it [00:01,  2.60it/s, Epoch=12, Val Loss=4.867446, Total Val Loss=4.900607, Total Val ACC=0.312208]\n",
            "421it [08:06,  1.15s/it, Epoch=13, LR=0.0001, Loss=4.676980, Total Loss=4.784485, Total ACC=0.331525]\n",
            "4it [00:01,  2.61it/s, Epoch=13, Val Loss=4.795825, Total Val Loss=4.825289, Total Val ACC=0.312295]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRa_ZEf1EsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9e5979da-675c-4c93-dc44-e0fac5c52165"
      },
      "source": [
        "plt.plot(loss_plot, label='train_loss')\n",
        "plt.plot(val_loss_plot, label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "K0dkEMlN7yb2",
        "outputId": "cbebf936-d15c-4332-df82-786582ae2246"
      },
      "source": [
        "plt.plot(acc_plot, label='train_acc')\n",
        "plt.plot(val_acc_plot, label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X82BU4j7yzH"
      },
      "source": [
        "def evaluate(tokens):\n",
        "    transformer.to(device)\n",
        "    decoder_input = torch.tensor([tar_tokenizer.txt2idx['sos_']] * tokens.size(0), dtype=torch.long).to(device)\n",
        "    output = decoder_input.unsqueeze(1).to(device)\n",
        "    enc_output = None\n",
        "    for i in range(decoder_len-1):        \n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        with torch.no_grad():\n",
        "            predictions, attention_weights, enc_output = transformer([tokens, output, enc_output])\n",
        "        \n",
        "        # select the last token from the seq_len dimension\n",
        "        predictions_ = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "        \n",
        "        predicted_id = torch.tensor(torch.argmax(predictions_, axis=-1), dtype=torch.int32)\n",
        "        \n",
        "        output = torch.cat([output, predicted_id], dim=-1)\n",
        "    output = output.cpu().numpy()\n",
        "    \n",
        "    summary_list = []\n",
        "    token_list = []\n",
        "    for token in output:\n",
        "        summary = tar_tokenizer.convert(token)\n",
        "        summary_list.append(summary)\n",
        "        token_list.append(token)\n",
        "    return summary_list, token_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnW1tdEl72_h",
        "outputId": "2940b4c8-90a0-43d5-f699-028904117e81"
      },
      "source": [
        "tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "preds = []\n",
        "tokens = []\n",
        "for batch, batch_item in tqdm_dataset:\n",
        "    output = evaluate(batch_item['src_token'].to(device))\n",
        "    preds.extend(output[0])\n",
        "    tokens.extend(output[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:11,  2.85s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY2CMPFv74h-",
        "outputId": "d698dfbe-5cd5-43bc-b6ee-2661b1d2c331"
      },
      "source": [
        "for i, (a, p) in enumerate(zip(df_val.summary, preds)):\n",
        "    print('정답 :', a)\n",
        "    print('예측 :', p)\n",
        "    print('=================================================================================')\n",
        "    if i == 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답 : 1일 도의회에 따르면 29일 경기도 교육청의 2020년도 예산안을 전액 삭감 조치하여 역점 사업으로 꼽히는 '꿈의 학교' '꿈의 대학'이 중단 위기에 놓였다.\n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 대회 개최한 ‘ 2019 년도 세계 수영 선수 권 대회 ’\n",
            "=================================================================================\n",
            "정답 : 수원시의회 채명기 의원은 29일 수원시 보건소에 대한 행정사무감사에서 난임부부 시술비 지원사업의 불용액이 많다는 점을 지적하며 사업 홍보에 관심을 기울일 것을 요청했다. \n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 ‘ 2019 년도 세계 수영 선수 권 대회 ’에서 개최하\n",
            "=================================================================================\n",
            "정답 : 수원시의회 이희승(민, 영통2·3동, 망포1·2동) 의원이 제347회 제2차 정례회 기간인 29일 수원시 문화예술과 행정사무감사에서 수원시립공연단 내 무예24기 시범단과 극단의 시너지 효과의 극대화와 순조롭고 효율적 운영을 위한 업무 분장을 제안했다.\n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 개최하여 2019 년도 세계 수영 선수 권 대회 대회 대회\n",
            "=================================================================================\n",
            "정답 : 미래HRD뉴엠에서 물류관리사, 행정사 시험 준비를 하는 사람들을 위해 근로자내일배움카드 국비전액지원 교육과정에 대한 무료상담을 지원하고 전액 무료로 수강을 진행하고 있으며 재직자국비지원에 대한 문의점은 홈페이지 상담전화 혹은 상담 문의를 통해 받고 있다.\n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 ‘ 2019 년도 세계 수영 선수 권 대회 ’에서 개최하\n",
            "=================================================================================\n",
            "정답 : 하남초등학교는 지난 달 19일에 열린 학교 알뜰시장 행사의 수익금을 전액 기부하기로한 학생들의 결정에 따라 하남시종합사회복지관을 찾아가 저소득가정 지원을 위한 후원금으로 전달을 하였다. \n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 개최하여 2019 년도 세계 수영 선수 권 대회 대회 대회\n",
            "=================================================================================\n",
            "정답 : 고희범 제주시장은 구리농수산물도매시장을 첫 방문해 '농수산물 제값 받기' 등을 관계자들과 논의하고, \"제주시의 농수산물 생산 체계를 보완하고, 구리도매시장을 제주시에 적극 홍보하겠다\"라고 밝혔다.\n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 ‘ 2019 년도 세계 수영 선수 권 대회 ’에서 개최하\n",
            "=================================================================================\n",
            "정답 : 지난 10월 말 우리나라 항공기 안에서 여성 승무월을 추행하여 벌금을 선고 받은 오드바야르 도르지 몽골 헌법재판소장은 보직에서 해임되었다. \n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 대회 개최한 ‘ 2019 년도 세계 수영 선수 권 대회 ’\n",
            "=================================================================================\n",
            "정답 : 여주시는 법무단지 및 신시가지 형성으로 인구가 급증한 오학동에 오학파출소를 신설해 1만6천여 명의 치안을 책임지고 주민들의 체감 안전도 상승에 기여할 것으로 기대된다.\n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 개최하여 2019 년도 세계 수영 선수 권 대회 대회 대회\n",
            "=================================================================================\n",
            "정답 : 시흥시는 가정에 적용하던 인센티브 제도를 운전자의  주행거리 단축실적에 따라서 10만 원까지 인센티브를 지급하는 제도를 2020년 80대를 모집해 확대 운영할 예정이라고 밝혔다.\n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 개최하여 2019 년도 세계 수영 선수 권 대회 대회 대회\n",
            "=================================================================================\n",
            "정답 : 평택시의회는 2일 ‘제210회 제2차 정례회 제2차 본회의’를 개최해, ‘평택시 화재대피용 방연마스크 비치 및 지원에 관한 조례안’ 등 37건의 조례안을 가결하고, 2019년도 추경 예산안에 대한 설명을 청취했다.\n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 개최하여 2019 년도 세계 수영 선수 권 대회 대회 대회\n",
            "=================================================================================\n",
            "정답 : 부천시는 오는 9일부터 12일까지 모집공고일 현재 부천시에 주민등록이 되어 있는 대학생을 대상으로 겨울방학 동안 행정업무를 보조할 부업의 기회를 제공하는데 대학원생 및 기존 부업대학생 참여자와 포기자는 제외한다. \n",
            "예측 :  한국 산업진 흥원이 2019 년도 세계 수영 선수 권 대회에서 개최되어 세계 수영 선수 권 대회 대회 대회 개최를 통해 2019 년도 세계 수영 선수 권 대회 개최한 ‘ 2019 년도 세계 수영 선수 권 대회 ’에서 개\n",
            "=================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wejRP_w277vq"
      },
      "source": [
        "tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
        "preds = []\n",
        "tokens = []\n",
        "for batch, batch_item in tqdm_dataset:\n",
        "    output = evaluate(batch_item['src_token'].to(device))\n",
        "    preds.extend(output[0])\n",
        "    tokens.extend(output[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkTryAgb79Wc"
      },
      "source": [
        "submission = pd.read_csv('data/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im4bm0nN7_D2"
      },
      "source": [
        "submission['summary'] = preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9inTje5d8BGl"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}